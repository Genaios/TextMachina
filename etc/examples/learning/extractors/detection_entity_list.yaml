# Config for everything related to dataset generation inputs
input_config:
    # Dataset metadata
    domain: news
    language: en

    # Dataset generator parameters
    quantity: 10
    random_sample_human: true

    # HuggingFace dataset params
    dataset: xsum
    dataset_text_column: document
    dataset_params:
        split: test

    # Prompt template
    template: >-
        Write a news article that includes the following entities: {entities}.
        \n\nArticle: 

    # Extractor params
    # The `entity_list` extractor automatically extract the entities
    # from the `dataset_text_column` of each sample in a dataset and 
    # includes them in the `{entities}` placeholder of the prompt template.
    # The `noun_list` extractor performs analogously to this one, but
    # the placeholder `{nouns}` is required, instead of `{entities}` as in
    # this `entity_list` case.
    extractor: entity_list
    max_input_tokens: 256
    
    
# Config for model instantiation
# Requires `OPENAI_API_KEY=<key>` environment variable.
model_config:
    provider: openai
    model_name: gpt-3.5-turbo-instruct
    api_type: COMPLETION
    threads: 8
    max_retries: 5
    timeout: 120
    
# Decoding args
generation_config:
    # Ignore use `max_tokens` to get automatic length estimation
    # max_tokens: 100
    temperature: 0.7
    presence_penalty: 1.0